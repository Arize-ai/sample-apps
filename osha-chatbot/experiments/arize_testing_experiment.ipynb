{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cam/Projects/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cam/Projects/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import editdistance\n",
    "from arize.experimental.datasets.core.client import ArizeDatasetsClient\n",
    "from arize.experimental.datasets.experiments.evaluators.base import (\n",
    "    EvaluationResult,\n",
    "    Evaluator,\n",
    ")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "arize_api_key = os.getenv(\"ARIZE_API_KEY\")\n",
    "arize_developer_key = os.getenv(\"ARIZE_DEVELOPER_KEY\")\n",
    "space_id = os.getenv(\"ARIZE_SPACE_ID\")\n",
    "dataset_id = \"RGF0YXNldDoxMzk2OmR5S3A=\"\n",
    "\n",
    "# Initialize Arize client\n",
    "client = ArizeDatasetsClient(developer_key=arize_developer_key, api_key=arize_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset fetched with 4 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes.session_id</th>\n",
       "      <th>attributes.llm.prompt_template.version</th>\n",
       "      <th>attributes.classification.confidence</th>\n",
       "      <th>attributes.reranker.top_k</th>\n",
       "      <th>attributes.llm.token_count.prompt</th>\n",
       "      <th>attributes.tool.input</th>\n",
       "      <th>attributes.llm.output_messages</th>\n",
       "      <th>attributes.tool.selection.matched_type</th>\n",
       "      <th>eval.contains_any_keyword.explanation</th>\n",
       "      <th>attributes.output.value</th>\n",
       "      <th>...</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>source_record_datasource</th>\n",
       "      <th>source_record_model_environment</th>\n",
       "      <th>source_record_timestamp</th>\n",
       "      <th>source_record_span_id</th>\n",
       "      <th>source_record_trace_id</th>\n",
       "      <th>events</th>\n",
       "      <th>attributes.llm.prompt_template.variables.query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>According to OSHA regulations, personal protec...</td>\n",
       "      <td>...</td>\n",
       "      <td>1ccb51c8-fdc3-4da3-b8f5-c976fd0a9ba9</td>\n",
       "      <td>1733188698905</td>\n",
       "      <td>1733188698905</td>\n",
       "      <td>17a0b3c2-2673-4a41-bf74-5212970b65bf</td>\n",
       "      <td>5</td>\n",
       "      <td>1732929553417</td>\n",
       "      <td>431c692148f7651d</td>\n",
       "      <td>98d9f6ef831db5a7eddefc3230126b7a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>There are no specific OSHA regulations that re...</td>\n",
       "      <td>...</td>\n",
       "      <td>975bfe47-8c8e-4a86-a0d0-e7ae6a6b7306</td>\n",
       "      <td>1733258753664</td>\n",
       "      <td>1733258753664</td>\n",
       "      <td>17a0b3c2-2673-4a41-bf74-5212970b65bf</td>\n",
       "      <td>5</td>\n",
       "      <td>1733249056262</td>\n",
       "      <td>6947713226d5e74c</td>\n",
       "      <td>a0be0107e62a339dc3c526cc7f3689f1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PPE stands for Personal Protective Equipment. ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1a88f276-7825-436b-9716-1ccfb611d160</td>\n",
       "      <td>1733258753664</td>\n",
       "      <td>1733258753664</td>\n",
       "      <td>17a0b3c2-2673-4a41-bf74-5212970b65bf</td>\n",
       "      <td>5</td>\n",
       "      <td>1733251141157</td>\n",
       "      <td>164b9146b00a9d2d</td>\n",
       "      <td>d284f4b9ee149ba6405bf6cd17e926d8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PPE stands for Personal Protective Equipment. ...</td>\n",
       "      <td>...</td>\n",
       "      <td>a9b86cba-a866-4e40-9a4e-c53880376afd</td>\n",
       "      <td>1733258753664</td>\n",
       "      <td>1733258753664</td>\n",
       "      <td>17a0b3c2-2673-4a41-bf74-5212970b65bf</td>\n",
       "      <td>5</td>\n",
       "      <td>1733251163954</td>\n",
       "      <td>53f7aa35f84ce647</td>\n",
       "      <td>90122c26a53590cf5c2a202ad33b407d</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  attributes.session_id attributes.llm.prompt_template.version  \\\n",
       "0                  None                                          \n",
       "1                  None                                          \n",
       "2                  None                                          \n",
       "3                  None                                          \n",
       "\n",
       "   attributes.classification.confidence  attributes.reranker.top_k  \\\n",
       "0                                   0.9                        NaN   \n",
       "1                                   0.8                        NaN   \n",
       "2                                   0.9                        NaN   \n",
       "3                                   0.9                        NaN   \n",
       "\n",
       "   attributes.llm.token_count.prompt attributes.tool.input  \\\n",
       "0                                NaN                  None   \n",
       "1                                NaN                  None   \n",
       "2                                NaN                  None   \n",
       "3                                NaN                  None   \n",
       "\n",
       "  attributes.llm.output_messages attributes.tool.selection.matched_type  \\\n",
       "0                           None                                   None   \n",
       "1                           None                                   None   \n",
       "2                           None                                   None   \n",
       "3                           None                                   None   \n",
       "\n",
       "  eval.contains_any_keyword.explanation  \\\n",
       "0                                  None   \n",
       "1                                  None   \n",
       "2                                  None   \n",
       "3                                  None   \n",
       "\n",
       "                             attributes.output.value  ...  \\\n",
       "0  According to OSHA regulations, personal protec...  ...   \n",
       "1  There are no specific OSHA regulations that re...  ...   \n",
       "2  PPE stands for Personal Protective Equipment. ...  ...   \n",
       "3  PPE stands for Personal Protective Equipment. ...  ...   \n",
       "\n",
       "                                     id     created_at     updated_at  \\\n",
       "0  1ccb51c8-fdc3-4da3-b8f5-c976fd0a9ba9  1733188698905  1733188698905   \n",
       "1  975bfe47-8c8e-4a86-a0d0-e7ae6a6b7306  1733258753664  1733258753664   \n",
       "2  1a88f276-7825-436b-9716-1ccfb611d160  1733258753664  1733258753664   \n",
       "3  a9b86cba-a866-4e40-9a4e-c53880376afd  1733258753664  1733258753664   \n",
       "\n",
       "               source_record_datasource source_record_model_environment  \\\n",
       "0  17a0b3c2-2673-4a41-bf74-5212970b65bf                               5   \n",
       "1  17a0b3c2-2673-4a41-bf74-5212970b65bf                               5   \n",
       "2  17a0b3c2-2673-4a41-bf74-5212970b65bf                               5   \n",
       "3  17a0b3c2-2673-4a41-bf74-5212970b65bf                               5   \n",
       "\n",
       "  source_record_timestamp source_record_span_id  \\\n",
       "0           1732929553417      431c692148f7651d   \n",
       "1           1733249056262      6947713226d5e74c   \n",
       "2           1733251141157      164b9146b00a9d2d   \n",
       "3           1733251163954      53f7aa35f84ce647   \n",
       "\n",
       "             source_record_trace_id events  \\\n",
       "0  98d9f6ef831db5a7eddefc3230126b7a   None   \n",
       "1  a0be0107e62a339dc3c526cc7f3689f1   None   \n",
       "2  d284f4b9ee149ba6405bf6cd17e926d8   None   \n",
       "3  90122c26a53590cf5c2a202ad33b407d   None   \n",
       "\n",
       "  attributes.llm.prompt_template.variables.query  \n",
       "0                                           None  \n",
       "1                                           None  \n",
       "2                                           None  \n",
       "3                                           None  \n",
       "\n",
       "[4 rows x 79 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = client.get_dataset(space_id=space_id, dataset_id=dataset_id)\n",
    "print(f\"Dataset fetched with {len(dataset)} rows\")\n",
    "display(dataset.head())  # Using display() for better notebook formatting\n",
    "\n",
    "\n",
    "# Define evaluator class\n",
    "class NotebookArizeEvaluator(Evaluator):\n",
    "    def evaluate(self, *, output: dict, dataset_row: dict, **_) -> EvaluationResult:\n",
    "        try:\n",
    "            # Check if we have an error\n",
    "            if output.get(\"error\"):\n",
    "                return EvaluationResult(\n",
    "                    explanation=f\"Error during processing: {output['error']}\",\n",
    "                    score=0.0,\n",
    "                    label=\"ERROR\",\n",
    "                )\n",
    "\n",
    "            model_output = output.get(\"output\", \"\")\n",
    "            expected = output.get(\"expected_response\", \"\")  # Get from output dictionary\n",
    "\n",
    "            # Check if we actually have both outputs to compare\n",
    "            if not model_output or not expected:\n",
    "                return EvaluationResult(\n",
    "                    explanation=\"Missing model output or expected response\",\n",
    "                    score=0.0,\n",
    "                    label=\"ERROR\",\n",
    "                )\n",
    "\n",
    "            # Calculate edit distance\n",
    "            distance = editdistance.eval(str(model_output), str(expected))\n",
    "            max_possible_distance = max(len(str(model_output)), len(str(expected)))\n",
    "            normalized_score = 1 - (\n",
    "                distance / max_possible_distance if max_possible_distance > 0 else 0\n",
    "            )\n",
    "\n",
    "            # Determine label based on score\n",
    "            if normalized_score > 0.9:\n",
    "                label = \"EXCELLENT\"\n",
    "            elif normalized_score > 0.7:\n",
    "                label = \"GOOD\"\n",
    "            elif normalized_score > 0.5:\n",
    "                label = \"FAIR\"\n",
    "            else:\n",
    "                label = \"POOR\"\n",
    "\n",
    "            return EvaluationResult(\n",
    "                explanation=f\"Edit distance: {distance}. Normalized score: {normalized_score:.2f}\",\n",
    "                score=normalized_score,\n",
    "                label=label,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            return EvaluationResult(\n",
    "                explanation=f\"Evaluation error: {str(e)}\", score=0.0, label=\"ERROR\"\n",
    "            )\n",
    "\n",
    "\n",
    "# Define task function anthropic.claude-3-5-sonnet-20241022-v2:0\n",
    "def notebook_task(dataset_row: dict) -> dict:\n",
    "    try:\n",
    "        query = dataset_row.get(\"attributes.input.value\", \"\")\n",
    "        print(f\"\\nQuery found: {query}\")\n",
    "\n",
    "        if not query or not isinstance(query, str):\n",
    "            print(f\"Invalid query format detected: {type(query)}\")\n",
    "            raise ValueError(f\"Invalid query format: {query}\")\n",
    "\n",
    "        # Import necessary components\n",
    "        import boto3\n",
    "        from tasks import IndexManager, QueryClassifier\n",
    "\n",
    "        # Initialize Bedrock client\n",
    "        bedrock_client = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "        # Create new index manager and query engine\n",
    "        index_manager = IndexManager(bedrock_client=bedrock_client)\n",
    "        query_engine = index_manager.get_query_engine()\n",
    "\n",
    "        # Initialize classifier with different model\n",
    "        different_model = \"anthropic.claude-3-sonnet-20240229-v1:0\"  # or whatever model you want to use anthropic.claude-3-haiku-20240307-v1:0\n",
    "        classifier = QueryClassifier(\n",
    "            query_engine=query_engine,\n",
    "            bedrock_client=bedrock_client,\n",
    "            model=different_model,\n",
    "        )\n",
    "\n",
    "        # Process the query using the classifier\n",
    "        category, confidence = classifier.classify_query(query)\n",
    "        response = classifier.get_response(query, category)\n",
    "\n",
    "        expected_response = dataset_row.get(\"attributes.output.value\", \"\")\n",
    "\n",
    "        return {\n",
    "            \"output\": response.response,\n",
    "            \"error\": None,\n",
    "            \"query\": query,\n",
    "            \"expected_response\": expected_response,\n",
    "            \"model_used\": different_model,\n",
    "            \"category\": category.value,\n",
    "            \"confidence\": confidence,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error processing query: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return {\n",
    "            \"output\": None,\n",
    "            \"error\": error_msg,\n",
    "            \"query\": query if \"query\" in locals() else None,\n",
    "            \"expected_response\": dataset_row.get(\"attributes.output.value\", \"\"),\n",
    "            \"model_used\": different_model if \"different_model\" in locals() else None,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m  arize.utils.logging | INFO | 🧪 Experiment started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:49:16,701 - arize.experimental.datasets.experiments.evaluators.executors - WARNING - 🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n",
      "running tasks |          | 0/4 (0.0%) | ⏳ 00:00<? | ?it/s2024-12-03 17:49:17,797 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query found: when should I wear ppe?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:49:21,472 - sentence_transformers.SentenceTransformer - INFO - 2 prompts are loaded, with the keys: ['query', 'text']\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 12.87it/s]\n",
      "running tasks |██▌       | 1/4 (25.0%) | ⏳ 00:28<01:24 | 28.04s/it2024-12-03 17:49:44,752 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query found: should I have a fire extinguisher in my miata?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:49:46,954 - sentence_transformers.SentenceTransformer - INFO - 2 prompts are loaded, with the keys: ['query', 'text']\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n",
      "running tasks |█████     | 2/4 (50.0%) | ⏳ 00:53<00:53 | 26.51s/it2024-12-03 17:50:10,224 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query found: what is ppe?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:50:12,576 - sentence_transformers.SentenceTransformer - INFO - 2 prompts are loaded, with the keys: ['query', 'text']\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 21.63it/s]\n",
      "running tasks |███████▌  | 3/4 (75.0%) | ⏳ 01:20<00:26 | 26.59s/it2024-12-03 17:50:36,934 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query found: what is ppe?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:50:39,646 - sentence_transformers.SentenceTransformer - INFO - 2 prompts are loaded, with the keys: ['query', 'text']\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s]\n",
      "running tasks |██████████| 4/4 (100.0%) | ⏳ 01:39<00:00 | 24.76s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m  arize.utils.logging | INFO | ✅ Task runs completed.\n",
      "Tasks Summary (12/03/24 05:50 PM -0800)\n",
      "---------------------------------------\n",
      "   n_examples  n_runs  n_errors\n",
      "0           4       4         0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-12-03 17:50:55,791 - arize.experimental.datasets.experiments.evaluators.executors - WARNING - 🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n",
      "running experiment evaluations |██████████| 4/4 (100.0%) | ⏳ 00:00<00:00 | 14.48it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m  arize.utils.logging | INFO | ✅ All evaluators completed.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "experiment_name = f\"Verisk_Experiment_{timestamp}\"\n",
    "\n",
    "# Run experiment with smaller batch for testing\n",
    "experiment = client.run_experiment(\n",
    "    space_id=space_id,\n",
    "    dataset_id=dataset_id,\n",
    "    task=notebook_task,\n",
    "    evaluators=[NotebookArizeEvaluator()],\n",
    "    experiment_name=experiment_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
